# RAG-based Query and Document Summary Engine 

Developed a document summarization and query engine using LlamaIndex, HuggingFace LLM, and 
embeddings from HuggingFace. 

Loaded documents from a directory and built a Retrieval Augmented Generation (RAG) pipeline 
utilizing a fine-tuned language model (Llama 2 7B) for generating responses to user queries based on 
the given context.  

Implemented a query engine to process questions and provide context-aware answers with efficient 
text summarization capabilities. 
